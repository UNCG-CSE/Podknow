{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Much of code is credit to: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.test.utils import datapath\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline\n",
    "from nltk.metrics.spearman import *\n",
    "from nltk.metrics import ContingencyMeasures\n",
    "import collections\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]\n",
      " [0.58127326 0.58127321 0.58127321 0.58127321 0.58127321 0.58127321\n",
      "  0.58127326 0.58127326 0.99999994 1.        ]]\n",
      "[[list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]]\n",
      "1\n",
      "[[0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n",
      "  1.         1.         0.58127319 0.58127314]\n",
      " [0.58127311 0.58127319 0.58127311 0.58127314 0.58127311 0.58127314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.         1.         0.58127319 0.58127314]]\n",
      "[[list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]\n",
      " [list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])\n",
      "  list([[], ['att_base', 'call_call', 'episodes_episode']])]]\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '['.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-a1856d97cbbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".txt_scrubbed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolderName\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mvalue0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalue3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mextraWords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, '['."
     ]
    }
   ],
   "source": [
    "def iterator(index):\n",
    "    \n",
    "    labels = ['ID','Name','Date','topicName','scrubbedtext']\n",
    "    podKnow_Data = pd.DataFrame.from_records(results, columns = labels)\n",
    "    \n",
    "    #isolate scrubbed text values and convert to lowercase to avoid duplicates\n",
    "    scrubbedData = str(podKnow_Data.iloc[index-1:index, 4].values).lower()\n",
    "    \n",
    "    #remove junk values\n",
    "    scrubbedData = scrubbedData.replace(\"\\\"\", \"\").replace(\",\", \"\").replace(\"\\'\",  \"\").splitlines()\n",
    "            \n",
    "    return scrubbedData\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\"\".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "    \n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "results = []\n",
    "counter = 0\n",
    "totalList = []\n",
    "\n",
    "\n",
    "saveLocation = r'C:\\Users\\Jeremy\\Desktop\\crime'\n",
    "for folderName,subfolders,fileName in os.walk(r'C:\\Users\\Jeremy\\Desktop\\crime'):\n",
    "    \n",
    "    \n",
    "    #try:   \n",
    "          for file in fileName:\n",
    "            if str(file.endswith(\".txt_scrubbed\")):\n",
    "                f = open(os.path.join(folderName,file),'rb')\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "            value0, value1, value2,value3, *extraWords = file.split('_')\n",
    "            value4 = data\n",
    "            rows = (value0,value1,value2,value3, value4)\n",
    "            results.append(rows)\n",
    "            \n",
    "            finalBigrams = \"\"\n",
    "            \n",
    "            counter = counter + 1\n",
    "            \n",
    "            data = iterator(counter)\n",
    "                                    \n",
    "            \n",
    "            print(len(data))\n",
    "            \n",
    "            data_words =  list(sent_to_words(data))\n",
    "            \n",
    "            tokens = nltk.wordpunct_tokenize(str(data))\n",
    "                        \n",
    "            bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "            \n",
    "    \n",
    "            #this block removes junk characters and only accepts words 3 letters or longer\n",
    "            finder = BigramCollocationFinder.from_words(tokens)\n",
    "\n",
    "            finder.apply_word_filter(lambda w: len(w) < 3)\n",
    "            \n",
    "            #find top 200 best bigrams\n",
    "            bigrams = list(sorted(finder.nbest(bigram_measures.likelihood_ratio, 20)))\n",
    "            \n",
    "            #convert bigrams to string for formatting\n",
    "            for x in bigrams: \n",
    "                finalBigrams += str(x)\n",
    "            \n",
    "\n",
    "            #remove junk values \n",
    "            data_words_bigrams = finalBigrams.replace(\"(\", \"\").replace(\")\", \"\").replace(\"'\", \" \").replace(\",\" ,\"\")\n",
    "\n",
    "            \n",
    "            data_words_bigrams = data_words_bigrams.split()\n",
    "            \n",
    "            finalBigrams = (list(sorted((data_words_bigrams))))\n",
    "            \n",
    "            #separate bigrams by '_' character and combine them into a single value \n",
    "            finalBigrams = [i+ '_' + j for i,j in zip(finalBigrams[::2], finalBigrams[1::2])]\n",
    "\n",
    "            nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "    \n",
    "            data_lemmatized = lemmatization(finalBigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "    \n",
    "            id2word = corpora.Dictionary(data_lemmatized)\n",
    "    \n",
    "            texts = data_lemmatized\n",
    "\n",
    "            \n",
    "            corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    \n",
    "    \n",
    "            lda_model = LdaMulticore(\n",
    "            corpus=corpus, num_topics=10, id2word=id2word,\n",
    "            workers=4, eval_every=None, passes=10, batch=True)\n",
    "\n",
    "        \n",
    "            lda_model.save(r\"model\" + str(counter))\n",
    "            \n",
    "            m1 = LdaMulticore.load(\"model1\")\n",
    "            m2 = LdaMulticore.load(\"model2\")\n",
    "            doc_lda = lda_model[corpus]\n",
    "\n",
    "\n",
    "            mdiff, annotation =  m1.diff(m2, distance='hellinger', annotation = True)\n",
    "            topic_diff = mdiff\n",
    "            print(topic_diff)\n",
    "            print(annotation)\n",
    "    \n",
    "\n",
    "    #except:\n",
    "     #   print(\"error\")\n",
    "              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "lda_display = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

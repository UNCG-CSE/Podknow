{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Much of code is credit to: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from gensim.test.utils import datapath\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets a specified index and returns text data from dataframe \n",
    "def iterator(index):\n",
    "    \n",
    "    labels = ['ID','Name','Date','topicName','scrubbedtext']\n",
    "    podKnow_Data = pd.DataFrame.from_records(results, columns = labels)\n",
    "    \n",
    "    #isolate scrubbed text values and convert to lowercase to avoid duplicates\n",
    "    scrubbedData = str(podKnow_Data.iloc[index-1:index, 4].values).lower()\n",
    "    \n",
    "    #remove junk values\n",
    "    scrubbedData = scrubbedData.replace(\"\\\"\", \"\").replace(\",\", \"\").replace(\"\\'\",  \"\").splitlines()\n",
    "            \n",
    "    return scrubbedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmitizes words\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\"\".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizes words    \n",
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputs an HTML file with pyLDAvis result        \n",
    "def printToHTML(ldaModel, corpus, id2word):\n",
    "    \n",
    "            lda_display = pyLDAvis.gensim.prepare(ldaModel, corpus, id2word, sort_topics=False)\n",
    "            pyLDAvis.enable_notebook()\n",
    "            \n",
    "            htmlFileName = file.replace(\".txt_scrubbed\", \".html\")\n",
    "            pyLDAvis.save_html(lda_display, htmlFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates bigrams, formats the data and produces a model as a result\n",
    "def formatDataAndModel(finalBigrams):\n",
    "            #remove junk values \n",
    "            data_words_bigrams = finalBigrams.replace(\"(\", \"\").replace(\")\", \"\").replace(\"'\", \" \").replace(\",\" ,\"\")\n",
    "            \n",
    "            data_words_bigrams = data_words_bigrams.split()\n",
    "            finalBigrams = (list((data_words_bigrams)))\n",
    "            \n",
    "            \n",
    "            #separate bigrams by '_' character and combine them into a single value \n",
    "            finalBigrams = [i+ '_' + j for i,j in zip(finalBigrams[::2], finalBigrams[1::2])]\n",
    "                        \n",
    "    \n",
    "            data_lemmatized = lemmatization(finalBigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "    \n",
    "            #maps IDs to words\n",
    "            id2word = corpora.Dictionary(data_lemmatized)\n",
    "    \n",
    "            #simply receives lemmitized text\n",
    "            texts = data_lemmatized\n",
    "    \n",
    "            #maps new lemmitized data to IDs\n",
    "            corpus = [id2word.doc2bow(text) for text in texts]\n",
    "    \n",
    "    \n",
    "            #builds model \n",
    "            lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           alpha= 'auto',\n",
    "                                           eval_every=5,\n",
    "                                           per_word_topics = True,\n",
    "                                           passes=20)\n",
    "    \n",
    "            doc_lda = lda_model[corpus]\n",
    "                        \n",
    "            printToHTML(lda_model, corpus, id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n",
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n",
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n",
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n",
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\models\\ldamodel.py:821: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  perwordbound = self.bound(chunk, subsample_ratio=subsample_ratio) / (subsample_ratio * corpus_words)\n",
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n",
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n",
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\gensim\\models\\ldamodel.py:821: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  perwordbound = self.bound(chunk, subsample_ratio=subsample_ratio) / (subsample_ratio * corpus_words)\n",
      "c:\\users\\frank einstein\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "counter = 0\n",
    "totalList = []\n",
    "\n",
    "\n",
    "saveLocation = r'C:\\Users\\Frank Einstein\\Podknow\\data\\transcripts\\gcsst\\scrubbed'\n",
    "for folderName,subfolders,fileName in os.walk(r'C:\\Users\\Frank Einstein\\Podknow\\data\\transcripts\\gcsst\\scrubbed'):\n",
    "    \n",
    "    \n",
    "    try:   \n",
    "          for file in fileName:\n",
    "            if str(file.endswith(\".txt_scrubbed\")):\n",
    "                f = open(os.path.join(folderName,file),'rb')\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "            value0, value1, value2,value3, *extraWords = file.split('_')\n",
    "            value4 = data\n",
    "            rows = (value0,value1,value2,value3, value4)\n",
    "            results.append(rows)\n",
    "            \n",
    "            finalBigrams = \"\"\n",
    "            \n",
    "            counter = counter + 1\n",
    "            \n",
    "            nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "            \n",
    "            #get all scrubbed data from a given podcast index\n",
    "            data = iterator(counter)\n",
    "            \n",
    "            data_words =  list(sent_to_words(data))\n",
    "\n",
    "            tokens = nltk.wordpunct_tokenize(str(data))\n",
    "            \n",
    "            bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "    \n",
    "            #this block removes junk characters and only accepts words 3 letters or longer\n",
    "            finder = BigramCollocationFinder.from_words(tokens)\n",
    "            finder.apply_word_filter(lambda w: len(w) < 3)\n",
    "            \n",
    "            #find top 200 best bigrams\n",
    "            bigrams = list(sorted(finder.nbest(bigram_measures.likelihood_ratio, 200)))\n",
    "            \n",
    "            \n",
    "            #convert bigrams to string for formatting\n",
    "            for x in bigrams: \n",
    "                finalBigrams += str(x)\n",
    "                \n",
    "                \n",
    "            formatDataAndModel(finalBigrams)\n",
    "           \n",
    "            \n",
    "    except:\n",
    "        print(\"error\")\n",
    "              \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
